{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GANs\n",
    "\n",
    "Neste exercício aprenderemos a desenvolver uma GAN simples utilizando Keras.\n",
    "\n",
    "Para isto, utilizaremos um dataset fictício que gera dados bidimensionais relativamente simples, e nossa rede GAN vai tentar replicar estes dados. \n",
    "\n",
    "Como primeiro passo, vamos criar o código para gerar este dataset e visualizar como ele se parece.\n",
    "\n",
    "A função fictícia irá ter 2 features. A primeira (*x*) está contida no intervalo entre \\[-1, 1\\]. A segunda (*y*) é dependente de *x* de acordo com a equação abaixo:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/svg.latex?\\Large&space;y=x^2\"/>\n",
    "\n",
    "O que faremos nesse exercício é tentar treinar uma GAN para gerar ambas as variáveis de modo realístico, com apenas a informação de que 2 variáveis devem ser geradas.\n",
    "\n",
    "Primeiro vamos criar uma função que gere instâncias <x,y> \"reais\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def real_function(x):\n",
    "    return np.multiply(x,x)\n",
    "\n",
    "def generate_samples(n_samples):\n",
    "    result = np.zeros((n_samples,2))\n",
    "    max_x,min_x = -1,+1\n",
    "    x = (np.random.rand(n_samples)*(max_x-min_x)) + min_x\n",
    "    result[:,0] = x\n",
    "    result[:,1] = real_function(x)\n",
    "    return result\n",
    "\n",
    "training_set = generate_samples(10000)\n",
    "test_set = generate_samples(10000)\n",
    "\n",
    "training_set, training_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos também criar uma função auxiliar para ajudar na visualização dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def print_samples(data):\n",
    "    plt.scatter(data[:,0], data[:, 1])\n",
    "    \n",
    "print_samples(training_set[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos uma base de treinamento, basta montar a nossa GAN.\n",
    "\n",
    "Relembrando o conteúdo da aula, a GAN é composta por um *discriminador* e um *gerador*. O discriminador é um classificador comum que aprende a distinguir instâncias reais de fictícias, e o gerador tenta aprender como gerar instâncias fictícias que enganem o discriminador.\n",
    "\n",
    "Vamos então partir para a implementação do discriminador, lembrando que a entrada é bidimensional, e a saída tem apenas uma dimensão prevendo se a instância é falsa ou verdadeira."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, Dropout, Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "def gan_discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=2, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "discriminator = gan_discriminator_model()\n",
    "opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme visto na aula, o gerador é dependente do discriminador para o treinamento, e vai tentar fazer com que o discriminador erre em suas predições.\n",
    "\n",
    "Para isto, precisamos criar um modelo *gerador* e um modelo *GAN*. O *gerador* irá partir de números aleatórios de tamanho arbitrário e tentar gerar números realísticos que sigam o padrão de nossos dados reais.\n",
    "\n",
    "O Processo de treinamento consiste em fazer com que o discriminador falhe em sua tarefa, o que vai ser possível se o gerador criar exemplos indistinguíveis dos dados reais. Como o *gerador* necessita do *discriminador* para seu treinamento, o Keras requer criarmos um outro modelo *GAN* que vai conectar o *gerador* e *discriminador*.\n",
    "\n",
    "Note que estamos usando a definição mais simples de custo para o gerador, o inverso do custo do discriminador.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 5\n",
    "\n",
    "def gan_generator_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=input_dim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(32))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(2, activation='tanh'))\n",
    "    return model\n",
    "\n",
    "def define_gan(generator, discriminator):\n",
    "    # connect generator and discriminator\n",
    "    \n",
    "    #O discriminador não deve ter seus pesos atualizados quando treinarmos o gerador\n",
    "    discriminator.trainable = False\n",
    "    ganInput = Input(shape=(input_dim,))\n",
    "    x = generator(ganInput)\n",
    "    ganOutput = discriminator(x)\n",
    "    gan = Model(inputs=ganInput, outputs=ganOutput)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return gan\n",
    "\n",
    "\n",
    "generator = gan_generator_model(input_dim)\n",
    "generator.summary()\n",
    "\n",
    "gan = define_gan(generator, discriminator)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos todos os modelos definidos, podemos realizar o treinamento efetivamente.\n",
    "\n",
    "Mas antes, vamos criar algumas funções auxiliares.\n",
    "\n",
    "A primeira `generate_batch_discriminator` vai criar um batch para treinamento do discriminador. De acordo com os valores nos parâmetros, metade do batch conterá instâncias reais (label y = 0) e metade do batch conterá instâncias falsas (label y = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_discriminator(batch_size, treino = True):\n",
    "    half_batch = int(batch_size/2)\n",
    "    \n",
    "    batch = np.zeros((batch_size, 2))\n",
    "    batch_y = np.zeros(batch_size)\n",
    "    \n",
    "    #Pega exemplos aleatoriamente da base de treinamento ou teste\n",
    "    if treino:\n",
    "        random_indices = np.random.choice(len(training_set), size=half_batch, replace=False)\n",
    "        batch[:half_batch, :] = training_set[random_indices, :]\n",
    "    else:\n",
    "        random_indices = np.random.choice(len(test_set), size=half_batch, replace=False)\n",
    "        batch[:half_batch, :] = test_set[random_indices, :]\n",
    "    #Labels das instâncias reais já são 0, entao nao há necessidade de mudar batch_y\n",
    "    \n",
    "    # A variável aleatória de entrada do gerador vai seguir uma distribuição normal\n",
    "    batch[half_batch:, :] = generator.predict(np.random.normal(0, 1, size=[half_batch, input_dim]))\n",
    "    batch_y[half_batch:] += 1. \n",
    "    return batch, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisaremos também de uma função semelhante para treinar o gerador, mas o batch de treinamento deve gerar apenas valores aleatórios, que serão alimentados ao modelo `gan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_gan(batch_size):\n",
    "    x_gan = np.random.normal(0, 1, size=[batch_size, input_dim])\n",
    "    #Neste caso criamos labels invertidos para os exemplos falsos, porque a funcao de custo\n",
    "    # do gerador é o inverso do discriminador\n",
    "    y_gan = np.zeros((batch_size)) \n",
    "    return x_gan,y_gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos criar a função de treinamento. Primeiro rodamos uma época de treinamento em batch do discriminador, para depois rodar uma época do gerador. Periódicamente visualizamos como as instâncias geradas se parecem. Durante o treinamento também iremos guardar as funcões de custo dos modelos e o percentual de acerto do discriminador em teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_images(samples):\n",
    "    plt.close()\n",
    "    print_samples(samples)\n",
    "    plt.show()\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10000\n",
    "\n",
    "test_size = 64\n",
    "half_test = int(test_size /2)\n",
    "\n",
    "#Erros do discriminador e gerador, e percentual de acerto no teste\n",
    "errors_discrim = np.zeros((epochs))\n",
    "errors_generator = np.zeros((epochs))\n",
    "perc_discrim = np.zeros((epochs))\n",
    "\n",
    "#Utilizado para a visualização de imagens não travar o treinamento\n",
    "plt.ion()\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    batch,batch_y = generate_batch_discriminator(batch_size, treino=True)       \n",
    "    #Preparando o discriminador para ter seus pesos atualizados\n",
    "    discriminator.trainable = True\n",
    "    errors_discrim[i],_ = discriminator.train_on_batch(batch, batch_y)\n",
    "    \n",
    "    \n",
    "    x_gan, y_gan = generate_batch_gan(batch_size)\n",
    "    discriminator.trainable = False\n",
    "    # update the generator via the discriminator's error\n",
    "    errors_generator[i] = gan.train_on_batch(x_gan, y_gan)\n",
    "    \n",
    "    #Gera um batch de teste e calcula a acuracia do discriminador\n",
    "    test_batch,test_y = generate_batch_discriminator(batch_size, treino=False) \n",
    "   \n",
    "    predictions =  (discriminator.predict(test_batch).ravel() > 0.5) * 1.\n",
    "    \n",
    "    perc_discrim[i] = sum(predictions == test_y)/test_size\n",
    "    #periodicamente\n",
    "    if i%1000 == 0:\n",
    "        print(\"epoch: \"+str(i))\n",
    "        print_images(generator.predict(np.random.normal(0, 1, size=[50, input_dim])))\n",
    "        print(\"Errors Discrimin: \" + str(errors_generator[i]))\n",
    "        print(\"Errors Generator:\" + str(errors_discrim[i]))\n",
    "        print(\"Perc Discrim:\" + str(perc_discrim[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o treinamento podemos visualizar se o treino deu certo comparando os dados reais com os gerados pela GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_samples(training_set[:100,:])\n",
    "print_samples(generator.predict(np.random.normal(0, 1, size=[100, input_dim])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos visualizar os erros dos modelos e o percentual de acerto do discriminador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors_generator, label='generator')\n",
    "plt.plot(errors_discrim, label='discriminator')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(perc_discrim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
